import gymnasium as gym
from stable_baselines3 import PPO, SAC
from sb3_contrib import TQC
from src.envs.gym_nav_env import GymNavEnv  # Updated import path
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv
import tensorboard
from torch.utils.tensorboard import SummaryWriter
from stable_baselines3.common.callbacks import BaseCallback

NUM_RAYS = 108
NUM_PEOPLE = 40
N_ENVS = 100

class TerminationStatsCallback(BaseCallback):
    def __init__(self, verbose=0, training_name="default"):
        super().__init__(verbose)
        
        # Updated writer path to keep root clean
        self.writer = SummaryWriter(log_dir="./logs/" + training_name)

        self.success = 0
        self.timeout = 0
        self.obstacle = 0
        self.human = 0
        self.episode_id = 0

    def _on_step(self) -> bool:
        """
        Viene chiamata ad ogni step, riceve infos dall'ambiente.
        """
        infos = self.locals["infos"]  # lista di info per ogni env del vec env
        dones = self.locals["dones"]

        for i, done in enumerate(dones):
            if done:
                info = infos[i]
                reason = info.get("termination_reason", None)

                if reason == "success":
                    self.success += 1
                elif reason == "timeout":
                    self.timeout += 1
                elif reason == "obstacle_collision":
                    self.obstacle += 1
                elif reason == "human_collision":
                    self.human += 1

                # Normalizzazione (somma=1)
                total = self.success + self.timeout + self.obstacle + self.human
                if total > 0:
                    self.writer.add_scalar("metrics/success_rate", self.success / total, self.episode_id)
                    self.writer.add_scalar("metrics/timeout_rate", self.timeout / total, self.episode_id)
                    self.writer.add_scalar("metrics/obstacle_collision_rate", self.obstacle / total, self.episode_id)
                    self.writer.add_scalar("metrics/human_collision_rate", self.human / total, self.episode_id)

                self.episode_id += 1

        return True

def make_env(rank: int):
    def _init():
        env = GymNavEnv(
            render_mode=None,
            num_rays=NUM_RAYS,
            num_people=NUM_PEOPLE,
        )
        env = Monitor(env)
        return env
    return _init

def main():
    use_subproc = True

    if use_subproc:
        env = SubprocVecEnv([make_env(i) for i in range(N_ENVS)])
    else:
        env = DummyVecEnv([make_env(i) for i in range(N_ENVS)])


    #model = PPO(
    #     "MlpPolicy",
    #     env,
    #     device="cpu",
    #     verbose=1,
    #     tensorboard_log="./logs/ppo_nav",  # Updated path
    #     learning_rate=3e-4,
    #     n_steps=2048,
    #     batch_size=64,
    #     n_epochs=10,
    #     gamma=0.99,
    #     gae_lambda=0.95,
    #     clip_range=0.2,
    #     ent_coef=0.0,
    # )

    total_timesteps = 30000000

    training_name = "30MSAC"

    model = SAC(
        "MlpPolicy",
        env,
        device="cpu",
        verbose=1,
        tensorboard_log="./logs/" + training_name,  # Updated path
        learning_rate=3e-4,
        batch_size=256,
        gamma=0.99,
        tau=0.005,
        train_freq=1,
        gradient_steps=1,
    )

    print(f"Training PPO with {N_ENVS} parallel envs, total_timesteps={total_timesteps}.")

    callback = TerminationStatsCallback(training_name=training_name)

    model.learn(
        total_timesteps=total_timesteps,
        tb_log_name="./logs/sac_nav" + training_name,
        callback=callback,
    )

    # Updated save path to checkpoints folder
    model.save("./checkpoints/" + training_name)

    print("Training completed and model saved.")

if __name__ == "__main__":
    main()